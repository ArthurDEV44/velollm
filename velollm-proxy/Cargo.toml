[package]
name = "velollm-proxy"
version.workspace = true
edition.workspace = true
authors.workspace = true
license.workspace = true
description = "High-performance proxy for local LLM inference optimization"

[[bin]]
name = "velollm-proxy"
path = "src/main.rs"

[dependencies]
# Workspace dependencies
tokio = { workspace = true }
serde = { workspace = true }
serde_json = { workspace = true }
anyhow = { workspace = true }
thiserror = { workspace = true }
tracing = { workspace = true }
tracing-subscriber = { workspace = true }
reqwest = { workspace = true, features = ["json", "stream"] }
chrono = { workspace = true }

# HTTP server
axum = { workspace = true }
tower = { workspace = true }
tower-http = { workspace = true }
hyper = { workspace = true }
hyper-util = { workspace = true }

# Async utilities
futures = { workspace = true }
async-stream = { workspace = true }
bytes = { workspace = true }

# UUID for request IDs
uuid = { workspace = true }

# JSON Schema validation
jsonschema = { workspace = true }

# Regex for JSON repair
regex = { workspace = true }

# Caching
lru = { workspace = true }
xxhash-rust = { workspace = true }

# Prometheus metrics
prometheus = "0.13"
lazy_static = "1.4"

# Embeddings (for semantic cache)
fastembed = { workspace = true, optional = true }

# Internal crates
velollm-core = { path = "../velollm-core" }

[features]
default = []
semantic-cache = ["fastembed"]

[dev-dependencies]
tokio-test = "0.4"
